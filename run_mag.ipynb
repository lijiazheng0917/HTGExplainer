{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiazhengli/anaconda3/envs/pt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from model.model_gcn import HTGNN, LinkPredictor\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from utils.utils import compute_metric, compute_loss\n",
    "from utils.data import load_MAG_data\n",
    "\n",
    "dgl.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_feats, val_labels):\n",
    "    val_mae_list, val_rmse_list = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (G_feat, (pos_label, neg_label)) in zip(val_feats, val_labels):\n",
    "\n",
    "            G_feat = G_feat.to(device)\n",
    "            pos_label = pos_label.to(device)\n",
    "            neg_label = neg_label.to(device)\n",
    "\n",
    "            h = model[0](G_feat, 'author')\n",
    "            pos_score = model[1](pos_label, h)\n",
    "            neg_score = model[1](neg_label, h)\n",
    "\n",
    "            loss = compute_loss(pos_score, neg_score, device)\n",
    "            auc, ap = compute_metric(pos_score, neg_score)\n",
    "    \n",
    "    return auc, ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mp2vec\n",
      "generating train, val, test sets \n"
     ]
    }
   ],
   "source": [
    "glist, label_dict = load_graphs('data/ogbn_graphs.bin')\n",
    "device = torch.device('cuda')\n",
    "time_window = 3\n",
    "\n",
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_MAG_data(glist, time_window, device)\n",
    "\n",
    "graph_atom = test_feats[0]\n",
    "model_out_path = 'output/OGBN-MAG'\n",
    "auc_list, ap_list = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Graph(num_nodes=17764, num_edges=74693,\n",
       "       ndata_schemes={}\n",
       "       edata_schemes={}),\n",
       " Graph(num_nodes=17764, num_edges=74693,\n",
       "       ndata_schemes={}\n",
       "       edata_schemes={}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "a = random.choice([0,1])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htgnn = HTGNN(graph=graph_atom, n_inp=128, n_hid=32, n_layers=2, n_heads=1, time_window=time_window, norm=True, device=device)\n",
    "predictor = LinkPredictor(n_inp=32, n_classes=1)\n",
    "model = nn.Sequential(htgnn, predictor).to(device)\n",
    "model.load_state_dict(torch.load('/home/jiazhengli/xdgnn/HTGNN/output/OGBN-MAG/checkpoint_HTGNN_0.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg, inverse_indices = dgl.khop_in_subgraph(train_feats[0], {'author': 3}, k=2, store_ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_graph(sampling_weights, temperature=1.0, bias=0.0, training=True):\n",
    "    \"\"\"\n",
    "    Implementation of the reparamerization trick to obtain a sample graph while maintaining the posibility to backprop.\n",
    "    :param sampling_weights: Weights provided by the mlp\n",
    "    :param temperature: annealing temperature to make the procedure more deterministic\n",
    "    :param bias: Bias on the weights to make samplign less deterministic\n",
    "    :param training: If set to false, the samplign will be entirely deterministic\n",
    "    :return: sample graph\n",
    "    \"\"\"\n",
    "    if training:\n",
    "        bias = bias + 0.0001  # If bias is 0, we run into problems\n",
    "        eps = (bias - (1-bias)) * torch.rand(sampling_weights.size()) + (1-bias) # uniform dist\n",
    "        gate_inputs = (torch.log(eps) - torch.log(1 - eps)).to('cuda')\n",
    "        \n",
    "        gate_inputs = (gate_inputs + sampling_weights) / temperature\n",
    "        graph =  torch.sigmoid(gate_inputs)\n",
    "    else:\n",
    "        graph = torch.sigmoid(sampling_weights)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model = nn.Sequential(\n",
    "    nn.Linear(32+32+32+32+7, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16,1)\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1d_absolute_sin_cos_embedding(pos_len, dim):\n",
    "    assert dim % 2 == 0, \"wrong dimension!\"\n",
    "    position_emb = torch.zeros(pos_len, dim, dtype=torch.float)\n",
    "    # i矩阵\n",
    "    i_matrix = torch.arange(dim//2, dtype=torch.float)\n",
    "    i_matrix /= dim / 2\n",
    "    i_matrix = torch.pow(10000, i_matrix)\n",
    "    i_matrix = 1 / i_matrix\n",
    "    i_matrix = i_matrix.to(torch.long)\n",
    "    # pos matrix\n",
    "    pos_vec = torch.arange(pos_len).to(torch.long)\n",
    "    # 矩阵相乘，pos变成列向量，i_matrix变成行向量\n",
    "    out = pos_vec[:, None] @ i_matrix[None, :]\n",
    "    # 奇/偶数列\n",
    "    emb_cos = torch.cos(out)\n",
    "    emb_sin = torch.sin(out)\n",
    "    # 赋值\n",
    "    position_emb[:, 0::2] = emb_sin\n",
    "    position_emb[:, 1::2] = emb_cos\n",
    "    return position_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_explainer_input(sg, inverse_indices, embed, node_id):\n",
    "    \"\"\"\n",
    "    Given the embeddign of the sample by the model that we wish to explain, this method construct the input to the mlp explainer model.\n",
    "    Depending on if the task is to explain a graph or a sample, this is done by either concatenating two or three embeddings.\n",
    "    :param pair: edge pair\n",
    "    :param embeds: embedding of all nodes in the graph\n",
    "    :param node_id: id of the node, not used for graph datasets\n",
    "    :return: concatenated embedding\n",
    "    \"\"\"\n",
    "    pos_emb = create_1d_absolute_sin_cos_embedding(pos_len=3, dim=32)\n",
    "    het = {'authorinstitution':torch.tensor([1,0,0,0,0,0,0]),'authorpaper':torch.tensor([0,1,0,0,0,0,0]), \\\n",
    "            'field_of_studypaper':torch.tensor([0,0,1,0,0,0,0]),'institutionauthor':torch.tensor([0,0,0,1,0,0,0]), \\\n",
    "            'paperpaper':torch.tensor([0,0,0,0,1,0,0]),'paperfield_of_study':torch.tensor([0,0,0,0,0,1,0]), \\\n",
    "            'paperauthor':torch.tensor([0,0,0,0,0,0,1])}\n",
    "\n",
    "    allemb = torch.tensor([]).to('cuda')\n",
    "    for srctype, etype, dsttype in sg.canonical_etypes:\n",
    "        src, dst = sg.edges(etype=etype)\n",
    "        new_src = sg.ndata[dgl.NID][srctype][src.long()]\n",
    "        new_dst = sg.ndata[dgl.NID][dsttype][dst.long()]\n",
    "        srcemb = embed[srctype][new_src.long()] # edge num, embsize\n",
    "        dstemb = embed[dsttype][new_dst.long()]\n",
    "        nemb = embed['author'][node_id].repeat(len(src), 1)\n",
    "        posemb = pos_emb[int(etype[-1])].repeat(len(src), 1).to('cuda')\n",
    "        hetemb = het[srctype+dsttype].repeat(len(src), 1).to('cuda')\n",
    "\n",
    "        srcemb = F.normalize(srcemb,dim=1)\n",
    "        dstemb = F.normalize(dstemb,dim=1)\n",
    "        posemb = F.normalize(posemb,dim=1)\n",
    "        hetemb = F.normalize(hetemb.float(),dim=1)\n",
    "        nemb = F.normalize(nemb,dim=1)\n",
    "\n",
    "        # with none\n",
    "        # eemb = torch.cat([srcemb,dstemb,nemb],dim=1)\n",
    "        # with all\n",
    "        eemb = torch.cat([srcemb,dstemb,posemb,hetemb,nemb],dim=1)\n",
    "\n",
    "        allemb = torch.cat([allemb,eemb],dim=0)\n",
    "\n",
    "    return allemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = {}\n",
    "for ntype in train_feats[0].ntypes:\n",
    "    embed[ntype] = model[0](train_feats[0].to('cuda'), ntype).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_expl = create_explainer_input(sg=sg, inverse_indices=inverse_indices, embed=embed, node_id=3).unsqueeze(0).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_weights = explainer_model(input_expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = sample_graph(sampling_weights, temperature=0.1, bias=0).squeeze().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[[2,3,4]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_graph_new(mask):\n",
    "        \n",
    "    new_mask = torch.zeros(mask.shape[0]).to('cuda')\n",
    "    _, idx = torch.sort(mask,descending=True)\n",
    "\n",
    "    top_idx = idx[:int(0.1*len(idx))]\n",
    "    new_mask[top_idx]=1\n",
    "\n",
    "    return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model[0](sg.to('cuda'),'author',edge_weight=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'author': 17764, 'field_of_study': 23109, 'institution': 2276, 'paper': 84344},\n",
       "      num_edges={('author', 'affiliated_with_t0', 'institution'): 40307, ('author', 'affiliated_with_t1', 'institution'): 40307, ('author', 'affiliated_with_t2', 'institution'): 40307, ('author', 'writes_t0', 'paper'): 256070, ('author', 'writes_t1', 'paper'): 235822, ('author', 'writes_t2', 'paper'): 315154, ('field_of_study', 'has_topic_r_t0', 'paper'): 310210, ('field_of_study', 'has_topic_r_t1', 'paper'): 281615, ('field_of_study', 'has_topic_r_t2', 'paper'): 258168, ('institution', 'affiliated_with_r_t0', 'author'): 40307, ('institution', 'affiliated_with_r_t1', 'author'): 40307, ('institution', 'affiliated_with_r_t2', 'author'): 40307, ('paper', 'cites_r_t0', 'paper'): 25054, ('paper', 'cites_r_t1', 'paper'): 22423, ('paper', 'cites_r_t2', 'paper'): 23017, ('paper', 'cites_t0', 'paper'): 25054, ('paper', 'cites_t1', 'paper'): 22423, ('paper', 'cites_t2', 'paper'): 23017, ('paper', 'has_topic_t0', 'field_of_study'): 310210, ('paper', 'has_topic_t1', 'field_of_study'): 281615, ('paper', 'has_topic_t2', 'field_of_study'): 258168, ('paper', 'writes_r_t0', 'author'): 256070, ('paper', 'writes_r_t1', 'author'): 235822, ('paper', 'writes_r_t2', 'author'): 315154},\n",
       "      metagraph=[('author', 'institution', 'affiliated_with_t0'), ('author', 'institution', 'affiliated_with_t1'), ('author', 'institution', 'affiliated_with_t2'), ('author', 'paper', 'writes_t0'), ('author', 'paper', 'writes_t1'), ('author', 'paper', 'writes_t2'), ('institution', 'author', 'affiliated_with_r_t0'), ('institution', 'author', 'affiliated_with_r_t1'), ('institution', 'author', 'affiliated_with_r_t2'), ('paper', 'paper', 'cites_r_t0'), ('paper', 'paper', 'cites_r_t1'), ('paper', 'paper', 'cites_r_t2'), ('paper', 'paper', 'cites_t0'), ('paper', 'paper', 'cites_t1'), ('paper', 'paper', 'cites_t2'), ('paper', 'field_of_study', 'has_topic_t0'), ('paper', 'field_of_study', 'has_topic_t1'), ('paper', 'field_of_study', 'has_topic_t2'), ('paper', 'author', 'writes_r_t0'), ('paper', 'author', 'writes_r_t1'), ('paper', 'author', 'writes_r_t2'), ('field_of_study', 'paper', 'has_topic_r_t0'), ('field_of_study', 'paper', 'has_topic_r_t1'), ('field_of_study', 'paper', 'has_topic_r_t2')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=17764, num_edges=74693,\n",
       "      ndata_schemes={}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Repeat time: 1---------------------\n",
      "# params: 126281\n",
      "Validation loss decreased (inf --> 0.693301).  Saving model ...\n",
      "Validation loss decreased (0.693301 --> 0.597250).  Saving model ...\n",
      "Validation loss decreased (0.597250 --> 0.561513).  Saving model ...\n",
      "Validation loss decreased (0.561513 --> 0.538988).  Saving model ...\n",
      "Validation loss decreased (0.538988 --> 0.518697).  Saving model ...\n",
      "Validation loss decreased (0.518697 --> 0.494623).  Saving model ...\n",
      "Validation loss decreased (0.494623 --> 0.482902).  Saving model ...\n",
      "Validation loss decreased (0.482902 --> 0.464226).  Saving model ...\n",
      "Validation loss decreased (0.464226 --> 0.448665).  Saving model ...\n",
      "Validation loss decreased (0.448665 --> 0.436250).  Saving model ...\n",
      "Validation loss decreased (0.436250 --> 0.423156).  Saving model ...\n",
      "Validation loss decreased (0.423156 --> 0.409451).  Saving model ...\n",
      "Validation loss decreased (0.409451 --> 0.398901).  Saving model ...\n",
      "Validation loss decreased (0.398901 --> 0.389806).  Saving model ...\n",
      "Validation loss decreased (0.389806 --> 0.382284).  Saving model ...\n",
      "Validation loss decreased (0.382284 --> 0.376524).  Saving model ...\n",
      "Validation loss decreased (0.376524 --> 0.370081).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Validation loss decreased (0.370081 --> 0.364305).  Saving model ...\n",
      "Validation loss decreased (0.364305 --> 0.356223).  Saving model ...\n",
      "Validation loss decreased (0.356223 --> 0.355400).  Saving model ...\n",
      "Validation loss decreased (0.355400 --> 0.348716).  Saving model ...\n",
      "Validation loss decreased (0.348716 --> 0.346019).  Saving model ...\n",
      "Validation loss decreased (0.346019 --> 0.343455).  Saving model ...\n",
      "Validation loss decreased (0.343455 --> 0.339557).  Saving model ...\n",
      "Validation loss decreased (0.339557 --> 0.337220).  Saving model ...\n",
      "Validation loss decreased (0.337220 --> 0.334118).  Saving model ...\n",
      "Validation loss decreased (0.334118 --> 0.332012).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "Validation loss decreased (0.332012 --> 0.331891).  Saving model ...\n",
      "Validation loss decreased (0.331891 --> 0.328846).  Saving model ...\n",
      "Validation loss decreased (0.328846 --> 0.328592).  Saving model ...\n",
      "Validation loss decreased (0.328592 --> 0.328180).  Saving model ...\n",
      "Validation loss decreased (0.328180 --> 0.326515).  Saving model ...\n",
      "Validation loss decreased (0.326515 --> 0.325586).  Saving model ...\n",
      "Validation loss decreased (0.325586 --> 0.323193).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Validation loss decreased (0.323193 --> 0.321638).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Validation loss decreased (0.321638 --> 0.317930).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "Validation loss decreased (0.317930 --> 0.314953).  Saving model ...\n",
      "Validation loss decreased (0.314953 --> 0.314423).  Saving model ...\n",
      "Validation loss decreased (0.314423 --> 0.311751).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Validation loss decreased (0.311751 --> 0.308557).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Validation loss decreased (0.308557 --> 0.307194).  Saving model ...\n",
      "Validation loss decreased (0.307194 --> 0.305127).  Saving model ...\n",
      "Validation loss decreased (0.305127 --> 0.300555).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Validation loss decreased (0.300555 --> 0.300235).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Validation loss decreased (0.300235 --> 0.295643).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "Validation loss decreased (0.295643 --> 0.295569).  Saving model ...\n",
      "Validation loss decreased (0.295569 --> 0.290725).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "Validation loss decreased (0.290725 --> 0.290187).  Saving model ...\n",
      "Validation loss decreased (0.290187 --> 0.281694).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "Validation loss decreased (0.281694 --> 0.280419).  Saving model ...\n",
      "Validation loss decreased (0.280419 --> 0.278089).  Saving model ...\n",
      "Validation loss decreased (0.278089 --> 0.277475).  Saving model ...\n",
      "Validation loss decreased (0.277475 --> 0.276799).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "Validation loss decreased (0.276799 --> 0.273965).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.273965 --> 0.272352).  Saving model ...\n",
      "Validation loss decreased (0.272352 --> 0.269702).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "Validation loss decreased (0.269702 --> 0.268453).  Saving model ...\n",
      "Validation loss decreased (0.268453 --> 0.267524).  Saving model ...\n",
      "Validation loss decreased (0.267524 --> 0.266992).  Saving model ...\n",
      "Validation loss decreased (0.266992 --> 0.265500).  Saving model ...\n",
      "Validation loss decreased (0.265500 --> 0.263469).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "Validation loss decreased (0.263469 --> 0.260928).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.260928 --> 0.257470).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.257470 --> 0.257099).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "Validation loss decreased (0.257099 --> 0.256640).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.256640 --> 0.256416).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.256416 --> 0.252182).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Validation loss decreased (0.252182 --> 0.249905).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "Validation loss decreased (0.249905 --> 0.247718).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.247718 --> 0.244699).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "Validation loss decreased (0.244699 --> 0.240852).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "EarlyStopping counter: 23 out of 50\n",
      "EarlyStopping counter: 24 out of 50\n",
      "EarlyStopping counter: 25 out of 50\n",
      "EarlyStopping counter: 26 out of 50\n",
      "EarlyStopping counter: 27 out of 50\n",
      "Validation loss decreased (0.240852 --> 0.239544).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Validation loss decreased (0.239544 --> 0.239035).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "Validation loss decreased (0.239035 --> 0.237370).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.237370 --> 0.237042).  Saving model ...\n",
      "Validation loss decreased (0.237042 --> 0.236678).  Saving model ...\n",
      "Validation loss decreased (0.236678 --> 0.233049).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "EarlyStopping counter: 23 out of 50\n",
      "EarlyStopping counter: 24 out of 50\n",
      "EarlyStopping counter: 25 out of 50\n",
      "Validation loss decreased (0.233049 --> 0.231850).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n",
      "EarlyStopping counter: 11 out of 50\n",
      "EarlyStopping counter: 12 out of 50\n",
      "EarlyStopping counter: 13 out of 50\n",
      "EarlyStopping counter: 14 out of 50\n",
      "EarlyStopping counter: 15 out of 50\n",
      "EarlyStopping counter: 16 out of 50\n",
      "EarlyStopping counter: 17 out of 50\n",
      "EarlyStopping counter: 18 out of 50\n",
      "EarlyStopping counter: 19 out of 50\n",
      "EarlyStopping counter: 20 out of 50\n",
      "EarlyStopping counter: 21 out of 50\n",
      "EarlyStopping counter: 22 out of 50\n",
      "EarlyStopping counter: 23 out of 50\n",
      "EarlyStopping counter: 24 out of 50\n",
      "EarlyStopping counter: 25 out of 50\n",
      "EarlyStopping counter: 26 out of 50\n",
      "EarlyStopping counter: 27 out of 50\n",
      "EarlyStopping counter: 28 out of 50\n",
      "EarlyStopping counter: 29 out of 50\n",
      "EarlyStopping counter: 30 out of 50\n",
      "EarlyStopping counter: 31 out of 50\n",
      "EarlyStopping counter: 32 out of 50\n",
      "EarlyStopping counter: 33 out of 50\n",
      "EarlyStopping counter: 34 out of 50\n",
      "EarlyStopping counter: 35 out of 50\n",
      "EarlyStopping counter: 36 out of 50\n",
      "EarlyStopping counter: 37 out of 50\n",
      "EarlyStopping counter: 38 out of 50\n",
      "EarlyStopping counter: 39 out of 50\n",
      "EarlyStopping counter: 40 out of 50\n",
      "EarlyStopping counter: 41 out of 50\n",
      "EarlyStopping counter: 42 out of 50\n",
      "EarlyStopping counter: 43 out of 50\n",
      "EarlyStopping counter: 44 out of 50\n",
      "EarlyStopping counter: 45 out of 50\n",
      "EarlyStopping counter: 46 out of 50\n",
      "EarlyStopping counter: 47 out of 50\n",
      "EarlyStopping counter: 48 out of 50\n",
      "EarlyStopping counter: 49 out of 50\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping\n",
      "auc: 0.8863316057268796, ap: 0.8618052569021026\n",
      "---------------Repeat time: 2---------------------\n",
      "# params: 126281\n",
      "Validation loss decreased (inf --> 0.663253).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "Validation loss decreased (0.663253 --> 0.591314).  Saving model ...\n",
      "Validation loss decreased (0.591314 --> 0.545162).  Saving model ...\n",
      "Validation loss decreased (0.545162 --> 0.543120).  Saving model ...\n",
      "Validation loss decreased (0.543120 --> 0.510387).  Saving model ...\n",
      "Validation loss decreased (0.510387 --> 0.509412).  Saving model ...\n",
      "Validation loss decreased (0.509412 --> 0.496051).  Saving model ...\n",
      "Validation loss decreased (0.496051 --> 0.481149).  Saving model ...\n",
      "Validation loss decreased (0.481149 --> 0.477559).  Saving model ...\n",
      "Validation loss decreased (0.477559 --> 0.472677).  Saving model ...\n",
      "Validation loss decreased (0.472677 --> 0.455618).  Saving model ...\n",
      "Validation loss decreased (0.455618 --> 0.432240).  Saving model ...\n",
      "Validation loss decreased (0.432240 --> 0.408606).  Saving model ...\n",
      "Validation loss decreased (0.408606 --> 0.397363).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "Validation loss decreased (0.397363 --> 0.393480).  Saving model ...\n",
      "Validation loss decreased (0.393480 --> 0.387731).  Saving model ...\n",
      "Validation loss decreased (0.387731 --> 0.381733).  Saving model ...\n",
      "Validation loss decreased (0.381733 --> 0.371112).  Saving model ...\n",
      "Validation loss decreased (0.371112 --> 0.367603).  Saving model ...\n",
      "Validation loss decreased (0.367603 --> 0.364686).  Saving model ...\n",
      "Validation loss decreased (0.364686 --> 0.361796).  Saving model ...\n",
      "Validation loss decreased (0.361796 --> 0.358497).  Saving model ...\n",
      "Validation loss decreased (0.358497 --> 0.358318).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 50\n",
      "EarlyStopping counter: 2 out of 50\n",
      "EarlyStopping counter: 3 out of 50\n",
      "EarlyStopping counter: 4 out of 50\n",
      "EarlyStopping counter: 5 out of 50\n",
      "EarlyStopping counter: 6 out of 50\n",
      "EarlyStopping counter: 7 out of 50\n",
      "EarlyStopping counter: 8 out of 50\n",
      "EarlyStopping counter: 9 out of 50\n",
      "EarlyStopping counter: 10 out of 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb Cell 6\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m     optim\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m auc, ap \u001b[39m=\u001b[39m evaluate(model, val_feats, val_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m early_stopping(loss, model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m early_stopping\u001b[39m.\u001b[39mearly_stop:\n",
      "\u001b[1;32m/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m         neg_score \u001b[39m=\u001b[39m model[\u001b[39m1\u001b[39m](neg_label, h)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m         loss \u001b[39m=\u001b[39m compute_loss(pos_score, neg_score, device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m         auc, ap \u001b[39m=\u001b[39m compute_metric(pos_score, neg_score)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_mag.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mreturn\u001b[39;00m auc, ap\n",
      "File \u001b[0;32m~/xdgnn/HTGNN/utils/utils.py:14\u001b[0m, in \u001b[0;36mcompute_metric\u001b[0;34m(pos_score, neg_score)\u001b[0m\n\u001b[1;32m     11\u001b[0m     label \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((torch\u001b[39m.\u001b[39mones(pos_score\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), torch\u001b[39m.\u001b[39mzeros(neg_score\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])))\n\u001b[1;32m     12\u001b[0m     pred_tag \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mround(torch\u001b[39m.\u001b[39msigmoid(pred))\n\u001b[0;32m---> 14\u001b[0m     auc \u001b[39m=\u001b[39m roc_auc_score(label, pred)\n\u001b[1;32m     15\u001b[0m     ap \u001b[39m=\u001b[39m average_precision_score(label, pred)\n\u001b[1;32m     16\u001b[0m \u001b[39m#     acc = accuracy_score(label, pred_tag)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m#     f1 = f1_score(label, pred_tag)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:570\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[39melif\u001b[39;00m y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    569\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_true)\n\u001b[0;32m--> 570\u001b[0m     y_true \u001b[39m=\u001b[39m label_binarize(y_true, classes\u001b[39m=\u001b[39;49mlabels)[:, \u001b[39m0\u001b[39m]\n\u001b[1;32m    571\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    572\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[1;32m    573\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    577\u001b[0m     )\n\u001b[1;32m    578\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:505\u001b[0m, in \u001b[0;36mlabel_binarize\u001b[0;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[39mif\u001b[39;00m pos_switch:\n\u001b[1;32m    503\u001b[0m     pos_label \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mneg_label\n\u001b[0;32m--> 505\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y)\n\u001b[1;32m    506\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmultioutput\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m y_type:\n\u001b[1;32m    507\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    508\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMultioutput target data is not supported with label binarization\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/sklearn/utils/multiclass.py:335\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    332\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39minput_name)\n\u001b[1;32m    333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[0;32m--> 335\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39;49munique(y)) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    336\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix  \u001b[39m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/numpy/lib/arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[1;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/numpy/lib/arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[1;32m    334\u001b[0m     aux \u001b[39m=\u001b[39m ar[perm]\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     ar\u001b[39m.\u001b[39;49msort()\n\u001b[1;32m    337\u001b[0m     aux \u001b[39m=\u001b[39m ar\n\u001b[1;32m    338\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(aux\u001b[39m.\u001b[39mshape, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mbool_)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(5):\n",
    "    htgnn = HTGNN(graph=graph_atom, n_inp=128, n_hid=32, n_layers=2, n_heads=1, time_window=time_window, norm=True, device=device)\n",
    "    predictor = LinkPredictor(n_inp=32, n_classes=1)\n",
    "    model = nn.Sequential(htgnn, predictor).to(device)\n",
    "\n",
    "    print(f'---------------Repeat time: {k+1}---------------------')\n",
    "    print(f'# params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=50, verbose=True, path=f'{model_out_path}/checkpoint_HTGNN_{k}.pt')\n",
    "    for epoch in range(500):\n",
    "        model.train()\n",
    "        for (G_feat, (pos_label, neg_label)) in zip(train_feats, train_labels):\n",
    "\n",
    "            G_feat = G_feat.to(device)\n",
    "\n",
    "            pos_label = pos_label.to(device)\n",
    "            neg_label = neg_label.to(device)\n",
    "\n",
    "            h = model[0](G_feat, 'author')\n",
    "\n",
    "            pos_score = model[1](pos_label, h)\n",
    "            neg_score = model[1](neg_label, h)\n",
    "            \n",
    "            loss = compute_loss(pos_score, neg_score, device)\n",
    "            auc, ap = compute_metric(pos_score, neg_score)\n",
    "\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        \n",
    "        auc, ap = evaluate(model, val_feats, val_labels)\n",
    "        early_stopping(loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(f'{model_out_path}/checkpoint_HTGNN_{k}.pt'))\n",
    "    auc, ap = evaluate(model, test_feats, test_labels)\n",
    "\n",
    "    print(f'auc: {auc}, ap: {ap}')\n",
    "    auc_list.append(auc)\n",
    "    ap_list.append(ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9100877512024033, 0.007723909849077316\n",
      "AP: 0.8917769733866674, 0.01237942594912229\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(f'AUC: {statistics.mean(auc_list)}, {statistics.stdev(auc_list)}')\n",
    "print(f'AP: {statistics.mean(ap_list)}, {statistics.stdev(ap_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "55bda1b7df90b08c6cf1f6311494e58e017df1e2a9c0703d9808f934a770372c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
