{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiazhengli/anaconda3/envs/pt/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl.data.utils import load_graphs\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from model.model_gcn import HTGNN, NodePredictor\n",
    "from utils.pytorchtools import EarlyStopping\n",
    "from utils.data import load_COVID_data\n",
    "\n",
    "dgl.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_feats, val_labels):\n",
    "    val_mae_list, val_rmse_list = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (G_feat, G_label) in zip(val_feats, val_labels):\n",
    "            h = model[0](G_feat.to(device), 'state')\n",
    "            pred = model[1](h)\n",
    "            label = G_label.nodes['state'].data['feat']\n",
    "            loss = F.l1_loss(pred, label.to(device))\n",
    "            rmse = torch.sqrt(F.mse_loss(pred, label.to(device)))\n",
    "\n",
    "            val_mae_list.append(loss.item())\n",
    "            val_rmse_list.append(rmse.item())\n",
    "            \n",
    "        loss = sum(val_mae_list) / len(val_mae_list)\n",
    "        rmse = sum(val_rmse_list) / len(val_rmse_list)\n",
    "\n",
    "    return loss, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "glist, _ = load_graphs('data/covid_graphs.bin')\n",
    "time_window = 7\n",
    "\n",
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_COVID_data(glist, time_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allow_zero_in_degree=True\n",
      "allow_zero_in_degree=True\n",
      "---------------Repeat time: 1---------------------\n",
      "# params: 6901\n",
      "502.4363059836601 1071.1216649244607\n",
      "Validation loss decreased (inf --> 1252.749552).  Saving model ...\n",
      "493.51030792365094 1057.095487489982\n",
      "Validation loss decreased (1252.749552 --> 1232.429688).  Saving model ...\n",
      "489.85471011348244 1051.966001518668\n",
      "Validation loss decreased (1232.429688 --> 1226.879889).  Saving model ...\n",
      "488.43917259988905 1048.5405896343761\n",
      "EarlyStopping counter: 1 out of 10\n",
      "488.67708391921934 1047.6134364904733\n",
      "EarlyStopping counter: 2 out of 10\n",
      "488.12886147693575 1046.3469489965426\n",
      "EarlyStopping counter: 3 out of 10\n",
      "487.18353467392876 1045.2581802515326\n",
      "EarlyStopping counter: 4 out of 10\n",
      "486.27649636409456 1043.9313387931147\n",
      "EarlyStopping counter: 5 out of 10\n",
      "485.60042332015684 1042.8984529698225\n",
      "EarlyStopping counter: 6 out of 10\n",
      "484.94683558468074 1041.9227992158399\n",
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb Cell 4\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m G_feat \u001b[39m=\u001b[39m train_feats[i]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m G_label \u001b[39m=\u001b[39m train_labels[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m h \u001b[39m=\u001b[39m model[\u001b[39m0\u001b[39;49m](G_feat\u001b[39m.\u001b[39;49mto(device), \u001b[39m'\u001b[39;49m\u001b[39mstate\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m pred \u001b[39m=\u001b[39m model[\u001b[39m1\u001b[39m](h)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.20.229.152/home/jiazhengli/xdgnn/HTGNN/run_covid_gcn.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m label \u001b[39m=\u001b[39m G_label\u001b[39m.\u001b[39mnodes[\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mfeat\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/xdgnn/HTGNN/model/model_gcn.py:243\u001b[0m, in \u001b[0;36mHTGNN.forward\u001b[0;34m(self, graph, predict_type, edge_weight)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m# gnn\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers):\n\u001b[0;32m--> 243\u001b[0m     inp_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgnn_layers[i](graph, inp_feat, edge_weight)\n\u001b[1;32m    245\u001b[0m out_feat \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([inp_feat[predict_type][ttype] \u001b[39mfor\u001b[39;00m ttype \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeframe])\n\u001b[1;32m    247\u001b[0m \u001b[39mreturn\u001b[39;00m out_feat\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/xdgnn/HTGNN/model/model_gcn.py:158\u001b[0m, in \u001b[0;36mHTGNNLayer.forward\u001b[0;34m(self, graph, node_features, edge_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m ttype \u001b[39m=\u001b[39m etype\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m edge_weight\u001b[39m==\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     dst_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mintra_rel_agg[etype](rel_graph, (node_features[stype][ttype], node_features[dtype][ttype]))\n\u001b[1;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     dst_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintra_rel_agg[etype](rel_graph, (node_features[stype][ttype], node_features[dtype][ttype]),edge_weight\u001b[39m=\u001b[39medge_weight)\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/dgl/nn/pytorch/conv/graphconv.py:428\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     \u001b[39m# aggregate first then mult W\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     graph\u001b[39m.\u001b[39msrcdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m feat_src\n\u001b[0;32m--> 428\u001b[0m     graph\u001b[39m.\u001b[39;49mupdate_all(aggregate_fn, fn\u001b[39m.\u001b[39;49msum(msg\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m'\u001b[39;49m, out\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mh\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m    429\u001b[0m     rst \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mdstdata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    430\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/dgl/heterograph.py:4900\u001b[0m, in \u001b[0;36mDGLHeteroGraph.update_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   4898\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ndata\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]\n\u001b[1;32m   4899\u001b[0m         ndata[key] \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mreplace_inf_with_zero(ndata[key])\n\u001b[0;32m-> 4900\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_n_repr(dtid, ALL, ndata)\n\u001b[1;32m   4901\u001b[0m \u001b[39melse\u001b[39;00m:   \u001b[39m# heterogeneous graph with number of relation types > 1\u001b[39;00m\n\u001b[1;32m   4902\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mis_builtin(message_func) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m core\u001b[39m.\u001b[39mis_builtin(reduce_func):\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/dgl/heterograph.py:4136\u001b[0m, in \u001b[0;36mDGLHeteroGraph._set_n_repr\u001b[0;34m(self, ntid, u, data)\u001b[0m\n\u001b[1;32m   4132\u001b[0m         \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m'\u001b[39m\u001b[39mPinned graph requires the node data to be pinned as well. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   4133\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mPlease pin the node data before assignment.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   4135\u001b[0m \u001b[39mif\u001b[39;00m is_all(u):\n\u001b[0;32m-> 4136\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_node_frames[ntid]\u001b[39m.\u001b[39;49mupdate(data)\n\u001b[1;32m   4137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4138\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_frames[ntid]\u001b[39m.\u001b[39mupdate_row(u, data)\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/_collections_abc.py:941\u001b[0m, in \u001b[0;36mMutableMapping.update\u001b[0;34m(self, other, **kwds)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Mapping):\n\u001b[1;32m    940\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m other:\n\u001b[0;32m--> 941\u001b[0m         \u001b[39mself\u001b[39m[key] \u001b[39m=\u001b[39m other[key]\n\u001b[1;32m    942\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mhasattr\u001b[39m(other, \u001b[39m\"\u001b[39m\u001b[39mkeys\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    943\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m other\u001b[39m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/anaconda3/envs/pt/lib/python3.9/site-packages/dgl/frame.py:634\u001b[0m, in \u001b[0;36mFrame.__setitem__\u001b[0;34m(self, name, data)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__setitem__\u001b[39m(\u001b[39mself\u001b[39m, name, data):\n\u001b[1;32m    625\u001b[0m     \u001b[39m\"\"\"Update the whole column.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[39m        The column data.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_column(name, data)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda')\n",
    "glist, _ = load_graphs('data/covid_graphs.bin')\n",
    "time_window = 7\n",
    "\n",
    "train_feats, train_labels, val_feats, val_labels, test_feats, test_labels = load_COVID_data(glist, time_window)\n",
    "\n",
    "graph_atom = test_feats[0]\n",
    "mae_list, rmse_list = [], []\n",
    "model_out_path = 'output/COVID19'\n",
    "\n",
    "for k in range(5):\n",
    "    htgnn = HTGNN(graph=graph_atom, n_inp=1, n_hid=8, n_layers=2, n_heads=1, time_window=time_window, norm=False, device=device)\n",
    "    predictor = NodePredictor(n_inp=8, n_classes=1)\n",
    "    model = nn.Sequential(htgnn, predictor).to(device)\n",
    "\n",
    "    print(f'---------------Repeat time: {k+1}---------------------')\n",
    "    print(f'# params: {sum(p.numel() for p in model.parameters() if p.requires_grad)}')\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=10, verbose=True, path=f'{model_out_path}/checkpoint_HTGNN_{k}.pt')\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=5e-4)\n",
    "    \n",
    "    train_mae_list, train_rmse_list = [], []\n",
    "    idx = np.random.permutation(len(train_feats))\n",
    "\n",
    "    for epoch in range(500):\n",
    "        model.train()\n",
    "        for i in idx:\n",
    "\n",
    "            G_feat = train_feats[i]\n",
    "            G_label = train_labels[i]\n",
    "            \n",
    "            h = model[0](G_feat.to(device), 'state')\n",
    "            pred = model[1](h)\n",
    "            label = G_label.nodes['state'].data['feat']\n",
    "            loss = F.l1_loss(pred, label.to(device))\n",
    "            rmse = torch.sqrt(F.mse_loss(pred, label.to(device)))\n",
    "\n",
    "            train_mae_list.append(loss.item())\n",
    "            train_rmse_list.append(rmse.item())\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        print(sum(train_mae_list) / len(train_mae_list), sum(train_rmse_list) / len(train_rmse_list))\n",
    "\n",
    "        loss, rmse = evaluate(model, val_feats, val_labels)\n",
    "        early_stopping(loss, model)\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load(f'{model_out_path}/checkpoint_HTGNN_{k}.pt'))\n",
    "    mae, rmse = evaluate(model, test_feats, test_labels)\n",
    "\n",
    "    print(f'mae: {mae}, rmse: {rmse}')\n",
    "    mae_list.append(mae)\n",
    "    rmse_list.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 555.4028908284505, 34.10586975793963\n",
      "RMSE: 1136.4205775960286, 65.13613775925027\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "print(f'MAE: {statistics.mean(mae_list)}, {statistics.stdev(mae_list)}')\n",
    "print(f'RMSE: {statistics.mean(rmse_list)}, {statistics.stdev(rmse_list)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "55bda1b7df90b08c6cf1f6311494e58e017df1e2a9c0703d9808f934a770372c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
